{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import concat\n",
    "from tensorflow import keras\n",
    "from time import localtime, strftime\n",
    "import tensorflow as tf\n",
    "import kerastuner as kt\n",
    "import statistics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getAllData(targetVar, path):\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "\n",
    "    col = df.columns.tolist()\n",
    "    \n",
    "    col.remove(targetVar)\n",
    "    \n",
    "    col += [targetVar] \n",
    "     \n",
    "    return df[col]\n",
    "\n",
    "\n",
    "def splitDataOnMonths(df):\n",
    "    \"\"\"Splits a dataframe into train, validation and test dataframes. \n",
    "    The data is split on specific months to avoid temporal overlapping.\n",
    "    \"\"\"\n",
    "\n",
    "    maxMonth = df[\"month\"].max()\n",
    "    \n",
    "    #(start, stop)\n",
    "    trainMonths = (0, 287)\n",
    "    \n",
    "    valMonths = (288, 312)\n",
    "    \n",
    "    testMonths = (313, 336)\n",
    "    \n",
    "    \n",
    "    def getMonthsBetween(df, start, stop):\n",
    "        return df[(df[\"month\"] >= start) & (df[\"month\"] <= stop) ]\n",
    "    \n",
    "    \n",
    "    train_df = getMonthsBetween(df, trainMonths[0], trainMonths[1])\n",
    "    test_df = getMonthsBetween(df, testMonths[0], testMonths[1])\n",
    "    val_df = getMonthsBetween(df, valMonths[0], valMonths[1])\n",
    "    \n",
    "    #print(train_df)\n",
    "    #print(val_df)\n",
    "    #print(test_df)\n",
    "    \n",
    "    return train_df, test_df, val_df\n",
    "\n",
    "    \n",
    "\n",
    " \n",
    " #%%\n",
    "def df_to_timeseriesMatrix(df, windowSize, nShifts, targetVar):\n",
    "    \"\"\"Creates time series matrix appropiate for supervised learning.\n",
    "    \"\"\"\n",
    "\n",
    "    #Tilldelar Y målvariablen.\n",
    "    Y = df[targetVar] \n",
    "    \n",
    "    #Tar bort målvariablen från resten av datasetet\n",
    "    col = df.columns.tolist()\n",
    "    col.remove(targetVar)\n",
    "    df = df[col]\n",
    "    \n",
    "    \n",
    "    #Antalet attribut/variabler\n",
    "    n_variables = len(df.columns)\n",
    "   \n",
    "    \n",
    "    \n",
    "    cols, names = list(), list()\n",
    "    \n",
    "\t\n",
    "    #Skapar tidsseriematrisen\n",
    "    for i in range(windowSize, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var{0}(t-{1})'.format(j+1, i-1)) for j in range(n_variables)]\n",
    "\t\n",
    "    #Om shifts är mindre än eller lika med noll så kommer den inte shifta. Men är minst shiftad 1. \n",
    "    if nShifts <= 0:\n",
    "        nShifts = -1\n",
    "    \n",
    "    #Siftar Y så många steg in i framtiden som ska predikteras\n",
    "    Y = Y.shift(-nShifts+1)\n",
    "    \n",
    "    #Lägger till Y i matrisen\n",
    "    cols.append(Y)\n",
    "    names+=[\"Y\"]\n",
    "    \n",
    "\t# sätt ihop\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    \n",
    "    #sortera\n",
    "    #agg = agg.sort_index(axis=1, ascending=False)\n",
    "    \n",
    "    #Ta bort windowSize första raderna (som har minst en NaN)\n",
    "    agg.dropna(inplace=True)\n",
    "\n",
    "    return agg\n",
    "\n",
    "\n",
    "\n",
    "def createNsplitTimeMatrix(df, windowSize, nShifts, targetVar):\n",
    "    \"\"\"Splits a time series matrix in predictors and target values.\n",
    "    \"\"\"\n",
    "    matrix = df_to_timeseriesMatrix(df, windowSize, nShifts, targetVar)\n",
    "    \n",
    "\n",
    "    dataY = matrix[\"Y\"].values\n",
    "    matrix = matrix.drop(columns=[\"Y\"])\n",
    "    dataX = matrix.values\n",
    "\n",
    "    return dataX, dataY\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def restructureData(df, windowSize, nShifts, targetVar):\n",
    "    \"\"\"Splits a dataframe into predictors X, and target values Y. \n",
    "    Every country is made into samples one by one to avoid spatial overlapping. \n",
    "    The target values are shifted nShift times.\n",
    "    \n",
    "    \"\"\"\n",
    "    countryMax = df[\"country_id\"].max()\n",
    "\n",
    "    X = np.array([])\n",
    "    Y = np.array([])\n",
    "    flag = 0\n",
    "    countries = list(set(df[\"country_id\"].values))\n",
    "    \n",
    "    for c_id in countries:\n",
    "        df_single_country = df[df[\"country_id\"] == c_id]\n",
    "        c_X, c_Y = createNsplitTimeMatrix(df_single_country, windowSize, nShifts, targetVar)\n",
    "        \n",
    "        if flag == 0:\n",
    "            X = c_X\n",
    "            Y = c_Y\n",
    "            flag = 1\n",
    "        else:\n",
    "            X = np.concatenate((X, c_X))\n",
    "            Y = np.concatenate((Y, c_Y))\n",
    "        \n",
    " \n",
    "    return X, Y\n",
    "       \n",
    "    \n",
    "#%%\n",
    "\n",
    "\n",
    "\n",
    "def buildModel(hiddenLayers, unitsPerHL, unitsInputLayer, batch_size=32): \n",
    "    \"\"\"Builds the model.\n",
    "    \"\"\"\n",
    "    METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auroc', curve='ROC'),\n",
    "      keras.metrics.AUC(name='aupr', curve='PR'),\n",
    "\n",
    "]\n",
    "    \n",
    "    #optimizer\n",
    "    ADAM = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=10e-6, amsgrad=False,\n",
    "    name='Adam'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    #storlekn på antal features\n",
    "    #input layer\n",
    "    model.add(keras.layers.Dense(unitsInputLayer, activation='relu', batch_size=batch_size))\n",
    "    \n",
    "    #hidden layers\n",
    "    for i in range(hiddenLayers):\n",
    "        model.add(keras.layers.Dense(unitsPerHL, activation='relu',batch_size=batch_size))\n",
    "        \n",
    "\n",
    "    #Output layers\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=ADAM, loss='binary_crossentropy', metrics=METRICS)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def build_tuner_model(hp):\n",
    "    \"\"\"Tuner function. Is used to find the optimal hyperparameters. \n",
    "    Max and min values for hyperparameters needs to be changed here.\n",
    "    \"\"\"\n",
    "    #min, max, step\n",
    "    #unitsInput = hp.Int('unitsInputLayer', 4, 15, step=2)\n",
    "    unitsHL = hp.Int('unitsPerHL', 4, 20, step=2)\n",
    "    hiddenLayers = hp.Int('hiddenLayers', 1, 15, step=2)\n",
    "    #batch size\n",
    "    bs = hp.Int('batch_size', 1, 140, step=20)\n",
    "    \n",
    "    METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auroc', curve='ROC'),\n",
    "      keras.metrics.AUC(name='aupr', curve='PR'),\n",
    "\n",
    "    ]\n",
    "    \n",
    "    #optimizer\n",
    "    ADAM = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=10e-6, amsgrad=False,\n",
    "    name='Adam'\n",
    "    )\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(unitsHL, activation='relu', batch_size=bs))\n",
    "    \n",
    "    for i in range(hiddenLayers):\n",
    "        \n",
    "        model.add(keras.layers.Dense(unitsHL, activation='relu',batch_size=bs))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=ADAM,loss='binary_crossentropy',metrics=METRICS)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def fitModel(model, trainX, trainY, valX, valY, epo, batch_size,  shuffle=False):\n",
    "    \"\"\"Fit model. Returns model and metric history.\n",
    "    \"\"\"\n",
    "    # fit network\n",
    "    history = model.fit(x=trainX, y=trainY,  validation_data=(valX, valY), epochs=epo, verbose=2, shuffle=shuffle, batch_size=batch_size)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predictModel(model, testX, nShifts, batch_size):\n",
    "    \"\"\"Precit model\n",
    "    \"\"\"\n",
    "    \n",
    "    print(testX.shape)\n",
    "    res = model.predict(testX, batch_size=batch_size)\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def plotPredict(res, testY, nShifts, windowSize, epochs, hiddenLayers, unitsPerHL, unitsInputLayer, batch_size, timeStamp, shuffle, onlyAfricaTest, onlyAfricaVal, onlyAfricaTrain) :\n",
    "    \"\"\"Plot predicitons and actual data. The hyperparameters that were used is shown at the top.\n",
    "    \"\"\"\n",
    "    \n",
    "    windowStart = 0\n",
    "    windowsStop = 205\n",
    "    predictStart = 130 - windowStart\n",
    "    predVal = testY[windowsStop:windowsStop+nShifts]    \n",
    "    \n",
    "    predVal_plot  = np.append(np.array([np.nan]*(windowsStop-windowStart)), predVal)\n",
    "    res_plot = np.append(np.array([np.nan]*(predictStart-1)), res.tolist())\n",
    "    \n",
    "    \n",
    "    print(\"Y-shape: \"+ str(testY.shape))\n",
    "    #testY = testY[nShifts:]\n",
    "    \n",
    "    plt.plot(res_plot, \"+r\", label='prediction')\n",
    "    plt.plot(testY[windowStart:windowsStop], label='actual')\n",
    "    plt.plot(predVal_plot, label=\"future val\")\n",
    "    \n",
    "    plt.xlabel('Steps (months?)')\n",
    "    plt.ylabel('Prob. of conflict')\n",
    "    \n",
    "    title = \"{0}\\n nShifts: {1} windowSize: {2} epochs: {3}\\n  hiddenLayers: {4}  unitsPerHL: {5}  unitsInputLayer: {6} \\n batch_size: {7} shuffle: {8} \\n onlyAfricaTest: {9} onlyAfricaVal: {10} onlyAfricaTrain: {11}\".format(timeStamp, nShifts, windowSize, epochs, hiddenLayers, unitsPerHL, unitsInputLayer, batch_size, shuffle, onlyAfricaTest, onlyAfricaVal, onlyAfricaTrain)\n",
    "  \n",
    "    plt.title(title)\n",
    "   \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "def plotMetrics(history, timeStamp):\n",
    "    \"\"\"Plot metrics from fitting.\n",
    "    \"\"\"\n",
    "    #print(history.history.keys())\n",
    "    auroc = history.history['auroc']\n",
    "    val_auroc = history.history['val_auroc']\n",
    "    \n",
    "    precision = history.history['precision']\n",
    "    val_precision = history.history['val_precision']\n",
    "    \n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    aupr = history.history['aupr']\n",
    "    val_aupr = history.history['val_aupr']\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    axs[0, 0].plot(auroc, label=\"Training\", color=\"g\")\n",
    "    axs[0, 0].plot(val_auroc, label=\"Validation\")\n",
    "    axs[0, 0].set_title(\"AUROC\")\n",
    "    \n",
    "    \n",
    "    axs[1, 0].plot(precision, color=\"g\")\n",
    "    axs[1, 0].plot(val_precision)\n",
    "    axs[1, 0].set_title(\"Precision\")\n",
    "    \n",
    "    #axs[0, 1].plot(accuracy, color=\"g\")\n",
    "    #axs[0, 1].plot(val_accuracy)\n",
    "    #axs[0, 1].set_title(\"Accuracy\")\n",
    "    \n",
    "    axs[0, 1].plot(aupr, color=\"g\")\n",
    "    axs[0, 1].plot(val_aupr)\n",
    "    axs[0, 1].set_title(\"AUPR\")\n",
    "    \n",
    "    axs[1, 1].plot(loss, color=\"g\")\n",
    "    axs[1, 1].plot(val_loss)\n",
    "    axs[1, 1].set_title(\"Loss\")\n",
    "    fig.legend()\n",
    "    fig.suptitle(timeStamp)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "\n",
    "def getEvaluateMetric(model, score):\n",
    "    \"\"\"Create dictionary of metric score and metric name from the model.evaluate method.\n",
    "    \"\"\"\n",
    "    \n",
    "    metrics = {}\n",
    "    for metric_name, value in zip(model.metrics_names, score):\n",
    "        metrics[metric_name] = value\n",
    "        \n",
    "    return metrics\n",
    "\n",
    "def getAverageFitMetric(history):\n",
    "    \n",
    "    mean_metrics = {}\n",
    "    for key in history.history.keys():\n",
    "        mean_metrics[key] = statistics.mean(history.history[key])\n",
    "        \n",
    "    return mean_metrics\n",
    "\n",
    "def calcBrierScore(results, testY):\n",
    "    \n",
    "    brierPerPrediction = []\n",
    "    results = [r for sublist in results for r in sublist]\n",
    "    \n",
    "    for p, v in zip(results, testY):\n",
    "        brier = (p-v)**2\n",
    "        brierPerPrediction.append(brier)\n",
    "    \n",
    "        \n",
    "    return statistics.mean(brierPerPrediction)\n",
    "    \n",
    "    \n",
    "    \n",
    "def onlyAfricaFilter(df, only=False):\n",
    "    \"\"\"Filter dataframe on countries outside of africa.\n",
    "    \"\"\"\n",
    "    if only:\n",
    "        df = df.loc[(df['e_regiongeo'] == 5) | (df['e_regiongeo'] == 6) | (df['e_regiongeo'] == 7)| (df['e_regiongeo'] == 8)| (df['e_regiongeo'] == 9)]\n",
    "        #Resets row indexing.\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "#https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "def saveModel(model, name):\n",
    "    \"\"\"Save model.\n",
    "    \"\"\"\n",
    "    model_json = model.to_json()\n",
    "    with open(str(name)+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "        \n",
    " \n",
    "    model.save_weights(str(name)+\".h5\")\n",
    "    print(\"Model saved\")\n",
    "\n",
    "\n",
    "\n",
    "def loadModel(name):\n",
    "    \"\"\"Load saved model.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    json_file = open(str(name)+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = tf.model_from_json(loaded_model_json)\n",
    "\n",
    "    model.load_weights(str(name)+\".h5\")\n",
    "    \n",
    "    return model, args_text\n",
    "\n",
    "\n",
    "def saveArgs(name, args):\n",
    "    f = open(\"{0}_args.txt\".format(name),\"w+\")\n",
    "    f.write(str(args))\n",
    "    \n",
    "def loadArgs(name):\n",
    "    f = open(\"{0}_args.txt\".format(name),\"r\")\n",
    "    args_text = f.read()\n",
    "    return args_text\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "def runModel(args):\n",
    "    targetVar = args[\"targetVar\"]\n",
    "    onlyAfricaTest = args[\"onlyAfricaTest\"]\n",
    "    onlyAfricaVal = args[\"onlyAfricaVal\"]\n",
    "    onlyAfricaTrain = args[\"onlyAfricaTrain\"]\n",
    "    windowSize = args[\"windowSize\"]\n",
    "    nShifts = args[\"nShifts\"]\n",
    "    epochs = args[\"epochs\"]\n",
    "    hiddenLayers = args[\"hiddenLayers\"]\n",
    "    unitsPerHL = args[\"unitsPerHL\"]\n",
    "    unitsInputLayer = args[\"unitsInputLayer\"]\n",
    "    shuffle = args[\"shuffle\"]\n",
    "    batch_size = args[\"batch_size\"]\n",
    "    timeStamp = args[\"timeStamp\"]\n",
    "    \n",
    "    \n",
    "    #Fetch data\n",
    "    df = getAllData(targetVar, path)\n",
    "    \n",
    "    #Remove the last two years. ViEWS test period is ending dec 2016.\n",
    "    df = df[df[\"month\"] <= 336]\n",
    "\n",
    "    #Split in train, test, val\n",
    "    train_df, test_df, val_df = splitDataOnMonths(df)\n",
    "    \n",
    "    #Filter data on africa\n",
    "    test_df = onlyAfricaFilter(test_df, onlyAfricaTest)\n",
    "    val_df = onlyAfricaFilter(val_df, onlyAfricaTest)\n",
    "    train_df = onlyAfricaFilter(train_df, onlyAfricaTrain)\n",
    "    \n",
    "    #Remove 'month'-column\n",
    "    train_df = train_df.drop(columns=[\"month\"])\n",
    "    val_df = val_df.drop(columns=[\"month\"])\n",
    "    test_df = test_df.drop(columns=[\"month\"])\n",
    "    \n",
    "    #Same scaler for all three data sets. \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    #Create training set\n",
    "    trainX, trainY = restructureData(train_df, windowSize, nShifts, targetVar)\n",
    "    print(\"Training set: Done \"+ str(trainX.shape))\n",
    "    \n",
    "    #Normalize\n",
    "    trainX_scaled = scaler.fit_transform(trainX)\n",
    "   \n",
    "    #Create val set\n",
    "    valX, valY = restructureData(val_df, windowSize, nShifts, targetVar)\n",
    "    print(\"Val set: Done \"+ str(valX.shape))\n",
    "    \n",
    "    #Normalize\n",
    "    valX_scaled = scaler.transform(valX)\n",
    "    \n",
    "    #Create test set\n",
    "    testX, testY = restructureData(test_df, windowSize, nShifts, targetVar)\n",
    "    print(\"Test set: Done \"+ str(testX.shape))\n",
    "    \n",
    "    #Normalize\n",
    "    testX_scaled = scaler.transform(testX)\n",
    "    \n",
    "    #Tune network by finding optimal hyperparameters. \n",
    "    if args[\"kerasTuner\"]:\n",
    "        \n",
    "        max_epochs = 100\n",
    "        \n",
    "        hp = kt.HyperParameters()      \n",
    "        \n",
    "        tuner = kt.Hyperband(build_tuner_model,'val_loss',max_epochs,hyperband_iterations=2)\n",
    "\n",
    "        tuner.search(trainX_scaled, trainY,validation_data=(valX_scaled, valY))\n",
    "        \n",
    "        hyperp = tuner.get_best_hyperparameters()\n",
    "       \n",
    "        tuner.results_summary()\n",
    "        \n",
    "        return False, False\n",
    "\n",
    "      \n",
    "    else:\n",
    "        #Normal run\n",
    "        #Build\n",
    "        model_1 = buildModel(hiddenLayers, unitsPerHL, unitsInputLayer, batch_size)\n",
    "        #Fit\n",
    "        model_1, history = fitModel(model_1, trainX_scaled, trainY, valX_scaled, valY, epochs, batch_size, shuffle=shuffle)\n",
    "        \n",
    "        #Print nework structure\n",
    "        model_1.summary()\n",
    "        \n",
    "        \n",
    "        test_eval = model_1.evaluate(testX_scaled, testY, batch_size=batch_size)\n",
    "        \n",
    "        #Predict.\n",
    "        res1 = predictModel(model_1, testX_scaled, nShifts, batch_size)\n",
    "        \n",
    "        #Plot predicitons. \n",
    "        #plotPredict(res1, testY, nShifts, windowSize, epochs, hiddenLayers, unitsPerHL, unitsInputLayer, batch_size, timeStamp, shuffle, onlyAfricaTest, onlyAfricaVal, onlyAfricaTrain)\n",
    "        \n",
    "        #Plot metrics.\n",
    "        plotMetrics(history, timeStamp)\n",
    "        print(args)\n",
    "        \n",
    "        print(getAverageFitMetric(history))\n",
    "        \n",
    "        print(getEvaluateMetric(model_1, test_eval))\n",
    "        \n",
    "        print(\"\\n BRIER:\\n\")\n",
    "        \n",
    "        print(calcBrierScore(res1, testY))\n",
    "        \n",
    "        metrics = {\"Brier\": calcBrierScore(res1, testY), \"Metrics\": getEvaluateMetric(model_1, test_eval)}\n",
    "        \n",
    "        return model_1, metrics\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path = \"X:/Exjobb/MOPS/data/processed/full_dataset.csv\"\n",
    "#path = \"C:/Users/Henrik/Downloads/full_dataset.csv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: Done (46480, 174)\n",
      "Val set: Done (901, 174)\n",
      "Test set: Done (848, 174)\n",
      "Train on 46480 samples, validate on 901 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-cc8793e77757>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mmodel_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs_mindre_modell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-105-04789813f6f7>\u001b[0m in \u001b[0;36mrunModel\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[0mmodel_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuildModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhiddenLayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munitsPerHL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munitsInputLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;31m#Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[0mmodel_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainX_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalX_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m         \u001b[1;31m#Print nework structure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-105-04789813f6f7>\u001b[0m in \u001b[0;36mfitModel\u001b[1;34m(model, trainX, trainY, valX, valY, epo, batch_size, shuffle)\u001b[0m\n\u001b[0;32m    256\u001b[0m     \"\"\"\n\u001b[0;32m    257\u001b[0m     \u001b[1;31m# fit network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "args_mindre_modell = {\n",
    "        \"targetVar\" : \"dummy_type_1\",\n",
    "        \"onlyAfricaTest\" : True,\n",
    "        \"onlyAfricaVal\" : False,\n",
    "        \"onlyAfricaTrain\" : False,\n",
    "        #Storleken på fönstret som ska inkluderas i ett sample.\n",
    "        \"windowSize\" : 6,\n",
    "        #Antalet förskjutningar.\n",
    "        \"nShifts\" : 3, \n",
    "        \"epochs\" : 15,\n",
    "        \"hiddenLayers\" : 2,\n",
    "        \"unitsPerHL\" : 9,\n",
    "        \"unitsInputLayer\" : 10,\n",
    "        #Blanda samples?\n",
    "        \"shuffle\" : True,\n",
    "        \"batch_size\" : 32,\n",
    "        \"timeStamp\" : strftime(\"%Y-%m-%d %H:%M:%S\", localtime()),\n",
    "        \"kerasTuner\": False\n",
    "}\n",
    "\n",
    "\n",
    "model_1, metrics_1 = runModel(args_mindre_modell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
