{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import concat\n",
    "from tensorflow import keras\n",
    "from time import localtime, strftime\n",
    "import tensorflow as tf\n",
    "import kerastuner as kt\n",
    "import statistics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getAllData(targetVar, path):\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    print(df.columns)\n",
    "    \n",
    "\n",
    "    col = df.columns.tolist()\n",
    "    \n",
    "    col.remove(targetVar)\n",
    "    \n",
    "    col += [targetVar] \n",
    "     \n",
    "    return df[col]\n",
    "\n",
    "\n",
    "def splitDataOnMonths(df):\n",
    "    \"\"\"Splits a dataframe into train, validation and test dataframes. \n",
    "    The data is split on specific months to avoid temporal overlapping.\n",
    "    \"\"\"\n",
    "\n",
    "    maxMonth = df[\"month\"].max()\n",
    "    \n",
    "    #GLOBALT\n",
    "    \n",
    "    #(start, stop)\n",
    "    #trainMonths = (0, 264)\n",
    "    \n",
    "    #valMonths = (265, 300)\n",
    "    \n",
    "    #testMonths = (301, 336)\n",
    "    \n",
    "    ##AFRIKA\n",
    "    \n",
    "    trainMonths = (0, 287)\n",
    "    \n",
    "    valMonths = (288, 323)\n",
    "    \n",
    "    testMonths = (324, 359)\n",
    "    \n",
    "    \n",
    "    def getMonthsBetween(df, start, stop):\n",
    "        return df[(df[\"month\"] >= start) & (df[\"month\"] <= stop) ]\n",
    "    \n",
    "    \n",
    "    train_df = getMonthsBetween(df, trainMonths[0], trainMonths[1])\n",
    "    test_df = getMonthsBetween(df, testMonths[0], testMonths[1])\n",
    "    val_df = getMonthsBetween(df, valMonths[0], valMonths[1])\n",
    "    \n",
    "    print(train_df)\n",
    "    print(val_df)\n",
    "    print(test_df)\n",
    "    \n",
    "    return train_df, test_df, val_df\n",
    "\n",
    "    \n",
    "\n",
    " \n",
    " #%%\n",
    "def df_to_timeseriesMatrix(df, windowSize, nShifts, targetVar):\n",
    "    \"\"\"Creates time series matrix appropiate for supervised learning.\n",
    "    \"\"\"\n",
    "\n",
    "    #Tilldelar Y målvariablen.\n",
    "    Y = df[targetVar] \n",
    "    \n",
    "    #Tar bort målvariablen från resten av datasetet\n",
    "    col = df.columns.tolist()\n",
    "    col.remove(targetVar)\n",
    "    df = df[col]\n",
    "    \n",
    "    \n",
    "    #Antalet attribut/variabler\n",
    "    n_variables = len(df.columns)\n",
    "   \n",
    "    \n",
    "    \n",
    "    cols, names = list(), list()\n",
    "    \n",
    "\t\n",
    "    #Skapar tidsseriematrisen\n",
    "    for i in range(windowSize, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var{0}(t-{1})'.format(j+1, i-1)) for j in range(n_variables)]\n",
    "\t\n",
    "    #Om shifts är mindre än eller lika med noll så kommer den inte shifta. Men är minst shiftad 1. \n",
    "    if nShifts <= 0:\n",
    "        nShifts = -1\n",
    "    \n",
    "    \n",
    "    #Siftar Y så många steg in i framtiden som ska predikteras\n",
    "    Y = Y.shift(-nShifts+1)\n",
    "    \n",
    "    #Lägger till Y i matrisen\n",
    "    cols.append(Y)\n",
    "    names+=[\"Y\"]\n",
    "    \n",
    "\t# sätt ihop\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    \n",
    "    #sortera\n",
    "    #agg = agg.sort_index(axis=1, ascending=False)\n",
    "    \n",
    "    #Ta bort windowSize första raderna (som har minst en NaN)\n",
    "    agg.dropna(inplace=True)\n",
    "\n",
    "    return agg\n",
    "\n",
    "\n",
    "\n",
    "def createNsplitTimeMatrix(df, windowSize, nShifts, targetVar):\n",
    "    \"\"\"Splits a time series matrix in predictors and target values.\n",
    "    \"\"\"\n",
    "    matrix = df_to_timeseriesMatrix(df, windowSize, nShifts, targetVar)\n",
    "    \n",
    "\n",
    "    dataY = matrix[\"Y\"].values\n",
    "    matrix = matrix.drop(columns=[\"Y\"])\n",
    "    dataX = matrix.values\n",
    "\n",
    "    return dataX, dataY\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def restructureData(df, windowSize, nShifts, targetVar):\n",
    "    \"\"\"Splits a dataframe into predictors X, and target values Y. \n",
    "    Every country is made into samples one by one to avoid spatial overlapping. \n",
    "    The target values are shifted nShift times.\n",
    "    \n",
    "    \"\"\"\n",
    "    countryMax = df[\"country_id\"].max()\n",
    "\n",
    "    X = np.array([])\n",
    "    Y = np.array([])\n",
    "    flag = 0\n",
    "    countries = list(set(df[\"country_id\"].values))\n",
    "    \n",
    "    for c_id in countries:\n",
    "        df_single_country = df[df[\"country_id\"] == c_id]\n",
    "        c_X, c_Y = createNsplitTimeMatrix(df_single_country, windowSize, nShifts, targetVar)\n",
    "        \n",
    "        if flag == 0:\n",
    "            X = c_X\n",
    "            Y = c_Y\n",
    "            flag = 1\n",
    "        else:\n",
    "            X = np.concatenate((X, c_X))\n",
    "            Y = np.concatenate((Y, c_Y))\n",
    "        \n",
    " \n",
    "    return X, Y\n",
    "       \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def buildModel(hiddenLayers, unitsPerHL, unitsInputLayer, batch_size=32): \n",
    "    \"\"\"Builds the model.\n",
    "    \"\"\"\n",
    "    METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auroc', curve='ROC'),\n",
    "      keras.metrics.AUC(name='aupr', curve='PR'),\n",
    "\n",
    "]\n",
    "    \n",
    "    #optimizer\n",
    "    ADAM = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=10e-6, amsgrad=False,\n",
    "    name='Adam'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    #storlekn på antal features\n",
    "    #input layer\n",
    "    model.add(keras.layers.Dense(unitsInputLayer, activation='relu', batch_size=batch_size))\n",
    "    \n",
    "    #hidden layers\n",
    "    for i in range(hiddenLayers):\n",
    "        model.add(keras.layers.Dense(unitsPerHL, activation='relu',batch_size=batch_size))\n",
    "        \n",
    "\n",
    "    #Output layers\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=ADAM, loss='binary_crossentropy', metrics=METRICS)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def build_tuner_model(hp):\n",
    "    \"\"\"Tuner function. Is used to find the optimal hyperparameters. \n",
    "    Max and min values for hyperparameters needs to be changed here.\n",
    "    \"\"\"\n",
    "    #min, max, step\n",
    "    #unitsInput = hp.Int('unitsInputLayer', 4, 15, step=2)\n",
    "    unitsHL = hp.Int('unitsPerHL', 4, 11, step=1)\n",
    "    hiddenLayers = hp.Int('hiddenLayers', 1, 5, step=1)\n",
    "    #batch size\n",
    "    bs = hp.Int('batch_size', 16, 40, step=4)\n",
    "    \n",
    "    METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auroc', curve='ROC'),\n",
    "      keras.metrics.AUC(name='aupr', curve='PR'),\n",
    "\n",
    "    ]\n",
    "    \n",
    "    #optimizer\n",
    "    ADAM = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=10e-6, amsgrad=False,\n",
    "    name='Adam'\n",
    "    )\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(unitsHL, activation='relu', batch_size=bs))\n",
    "    \n",
    "    for i in range(hiddenLayers):\n",
    "        \n",
    "        model.add(keras.layers.Dense(unitsHL, activation='relu',batch_size=bs))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=ADAM,loss='binary_crossentropy',metrics=METRICS)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def fitModel(model, trainX, trainY, valX, valY, epo, batch_size,  shuffle=False):\n",
    "    \"\"\"Fit model. Returns model and metric history.\n",
    "    \"\"\"\n",
    "    # fit network\n",
    "    history = model.fit(x=trainX, y=trainY,  validation_data=(valX, valY), epochs=epo, verbose=2, shuffle=shuffle, batch_size=batch_size)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predictModel(model, testX, nShifts, batch_size):\n",
    "    \"\"\"Precit model\n",
    "    \"\"\"\n",
    "    \n",
    "    print(testX.shape)\n",
    "    res = model.predict(testX, batch_size=batch_size)\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def plotPredict(res, testY, nShifts, windowSize, epochs, hiddenLayers, unitsPerHL, unitsInputLayer, batch_size, timeStamp, shuffle, onlyAfricaTest, onlyAfricaVal, onlyAfricaTrain) :\n",
    "    \"\"\"Plot predicitons and actual data. The hyperparameters that were used is shown at the top.\n",
    "    \"\"\"\n",
    "    \n",
    "    windowStart = 0\n",
    "    windowsStop = 205\n",
    "    predictStart = 130 - windowStart\n",
    "    predVal = testY[windowsStop:windowsStop+nShifts]    \n",
    "    \n",
    "    predVal_plot  = np.append(np.array([np.nan]*(windowsStop-windowStart)), predVal)\n",
    "    res_plot = np.append(np.array([np.nan]*(predictStart-1)), res.tolist())\n",
    "    \n",
    "    \n",
    "    print(\"Y-shape: \"+ str(testY.shape))\n",
    "    #testY = testY[nShifts:]\n",
    "    \n",
    "    plt.plot(res_plot, \"+r\", label='prediction')\n",
    "    plt.plot(testY[windowStart:windowsStop], label='actual')\n",
    "    plt.plot(predVal_plot, label=\"future val\")\n",
    "    \n",
    "    plt.xlabel('Steps (months?)')\n",
    "    plt.ylabel('Prob. of conflict')\n",
    "    \n",
    "    title = \"{0}\\n nShifts: {1} windowSize: {2} epochs: {3}\\n  hiddenLayers: {4}  unitsPerHL: {5}  unitsInputLayer: {6} \\n batch_size: {7} shuffle: {8} \\n onlyAfricaTest: {9} onlyAfricaVal: {10} onlyAfricaTrain: {11}\".format(timeStamp, nShifts, windowSize, epochs, hiddenLayers, unitsPerHL, unitsInputLayer, batch_size, shuffle, onlyAfricaTest, onlyAfricaVal, onlyAfricaTrain)\n",
    "  \n",
    "    plt.title(title)\n",
    "   \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plotMetrics(history, timeStamp):\n",
    "    \"\"\"Plot metrics from fitting.\n",
    "    \"\"\"\n",
    "    #print(history.history.keys())\n",
    "    auroc = history.history['auroc']\n",
    "    val_auroc = history.history['val_auroc']\n",
    "    \n",
    "    precision = history.history['precision']\n",
    "    val_precision = history.history['val_precision']\n",
    "    \n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    aupr = history.history['aupr']\n",
    "    val_aupr = history.history['val_aupr']\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    axs[0, 0].plot(auroc, label=\"Training\", color=\"g\")\n",
    "    axs[0, 0].plot(val_auroc, label=\"Validation\")\n",
    "    axs[0, 0].set_title(\"AUROC\")\n",
    "    \n",
    "    \n",
    "    axs[1, 0].plot(precision, color=\"g\")\n",
    "    axs[1, 0].plot(val_precision)\n",
    "    axs[1, 0].set_title(\"Precision\")\n",
    "    \n",
    "    #axs[0, 1].plot(accuracy, color=\"g\")\n",
    "    #axs[0, 1].plot(val_accuracy)\n",
    "    #axs[0, 1].set_title(\"Accuracy\")\n",
    "    \n",
    "    axs[0, 1].plot(aupr, color=\"g\")\n",
    "    axs[0, 1].plot(val_aupr)\n",
    "    axs[0, 1].set_title(\"AUPR\")\n",
    "    \n",
    "    axs[1, 1].plot(loss, color=\"g\")\n",
    "    axs[1, 1].plot(val_loss)\n",
    "    axs[1, 1].set_title(\"Loss\")\n",
    "    fig.legend()\n",
    "    fig.suptitle(timeStamp)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "\n",
    "def getEvaluateMetric(model, score):\n",
    "    \"\"\"Create dictionary of metric score and metric name from the model.evaluate method.\n",
    "    \"\"\"\n",
    "    \n",
    "    metrics = {}\n",
    "    for metric_name, value in zip(model.metrics_names, score):\n",
    "        metrics[metric_name] = value\n",
    "        \n",
    "    return metrics\n",
    "\n",
    "def getAverageFitMetric(history):\n",
    "    \n",
    "    mean_metrics = {}\n",
    "    for key in history.history.keys():\n",
    "        mean_metrics[key] = statistics.mean(history.history[key])\n",
    "        \n",
    "    return mean_metrics\n",
    "\n",
    "def calcBrierScore(results, testY):\n",
    "    \n",
    "    brierPerPrediction = []\n",
    "    results = [r for sublist in results for r in sublist]\n",
    "    \n",
    "    for p, v in zip(results, testY):\n",
    "        brier = (p-v)**2\n",
    "        brierPerPrediction.append(brier)\n",
    "    \n",
    "        \n",
    "    return statistics.mean(brierPerPrediction)\n",
    "    \n",
    "    \n",
    "    \n",
    "def onlyAfricaFilter(df, only=False):\n",
    "    \"\"\"Filter dataframe on countries outside of africa.\n",
    "    \"\"\"\n",
    "    if only:\n",
    "        df = df.loc[(df['e_regiongeo'] == 5) | (df['e_regiongeo'] == 6) | (df['e_regiongeo'] == 7)| (df['e_regiongeo'] == 8)| (df['e_regiongeo'] == 9)]\n",
    "        #Resets row indexing.\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "#https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "def saveModel(model, name):\n",
    "    \"\"\"Save model.\n",
    "    \"\"\"\n",
    "    model_json = model.to_json()\n",
    "    with open(str(name)+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "        \n",
    " \n",
    "    model.save_weights(str(name)+\".h5\")\n",
    "    print(\"Model saved\")\n",
    "\n",
    "\n",
    "\n",
    "def loadModel(name):\n",
    "    \"\"\"Load saved model.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    json_file = open(str(name)+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = tf.model_from_json(loaded_model_json)\n",
    "\n",
    "    model.load_weights(str(name)+\".h5\")\n",
    "    \n",
    "    return model, args_text\n",
    "\n",
    "\n",
    "def saveArgs(name, args):\n",
    "    f = open(\"{0}_args.txt\".format(name),\"w+\")\n",
    "    f.write(str(args))\n",
    "    \n",
    "def loadArgs(name):\n",
    "    f = open(\"{0}_args.txt\".format(name),\"r\")\n",
    "    args_text = f.read()\n",
    "    return args_text\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "def runModel(args):\n",
    "    targetVar = args[\"targetVar\"]\n",
    "    onlyAfricaTest = args[\"onlyAfricaTest\"]\n",
    "    onlyAfricaVal = args[\"onlyAfricaVal\"]\n",
    "    onlyAfricaTrain = args[\"onlyAfricaTrain\"]\n",
    "    windowSize = args[\"windowSize\"]\n",
    "    nShifts = args[\"nShifts\"]\n",
    "    epochs = args[\"epochs\"]\n",
    "    hiddenLayers = args[\"hiddenLayers\"]\n",
    "    unitsPerHL = args[\"unitsPerHL\"]\n",
    "    unitsInputLayer = args[\"unitsInputLayer\"]\n",
    "    shuffle = args[\"shuffle\"]\n",
    "    batch_size = args[\"batch_size\"]\n",
    "    timeStamp = args[\"timeStamp\"]\n",
    "    \n",
    "    \n",
    "    #Fetch data\n",
    "    df = getAllData(targetVar, path)\n",
    "    \n",
    "    #Remove the last two years. ViEWS test period is ending dec 2016.\n",
    "    #df = df[df[\"month\"] <= 336]\n",
    "    \n",
    "    print(df.columns)\n",
    "\n",
    "    #Split in train, test, val\n",
    "    train_df, test_df, val_df = splitDataOnMonths(df)\n",
    "    \n",
    "    #Filter data on africa\n",
    "    test_df = onlyAfricaFilter(test_df, onlyAfricaTest)\n",
    "    val_df = onlyAfricaFilter(val_df, onlyAfricaTest)\n",
    "    train_df = onlyAfricaFilter(train_df, onlyAfricaTrain)\n",
    "    \n",
    "    #Remove 'month'-column\n",
    "    train_df = train_df.drop(columns=[\"month\"])\n",
    "    val_df = val_df.drop(columns=[\"month\"])\n",
    "    test_df = test_df.drop(columns=[\"month\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Same scaler for all three data sets. \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    #Create training set\n",
    "    trainX, trainY = restructureData(train_df, windowSize, nShifts, targetVar)\n",
    "    print(\"Training set: Done \"+ str(trainX.shape))\n",
    "    \n",
    "    #Normalize\n",
    "    trainX_scaled = scaler.fit_transform(trainX)\n",
    "   \n",
    "    #Create val set\n",
    "    valX, valY = restructureData(val_df, windowSize, nShifts, targetVar)\n",
    "    print(\"Val set: Done \"+ str(valX.shape))\n",
    "    \n",
    "    #Normalize\n",
    "    valX_scaled = scaler.transform(valX)\n",
    "    \n",
    "    #Create test set\n",
    "    testX, testY = restructureData(test_df, windowSize, nShifts, targetVar)\n",
    "    print(\"Test set: Done \"+ str(testX.shape))\n",
    "    \n",
    "    #Normalize\n",
    "    testX_scaled = scaler.transform(testX)\n",
    "    \n",
    "    #Tune network by finding optimal hyperparameters. \n",
    "    if args[\"kerasTuner\"]:\n",
    "        \n",
    "        max_epochs = 100\n",
    "        \n",
    "        hp = kt.HyperParameters()      \n",
    "        \n",
    "        tuner = kt.Hyperband(build_tuner_model,'val_loss',max_epochs,hyperband_iterations=2)\n",
    "\n",
    "        tuner.search(trainX_scaled, trainY,validation_data=(valX_scaled, valY))\n",
    "        \n",
    "        hyperp = tuner.get_best_hyperparameters()\n",
    "       \n",
    "        tuner.results_summary()\n",
    "        \n",
    "        return False, False\n",
    "\n",
    "      \n",
    "    else:\n",
    "        #Normal run\n",
    "        #Build\n",
    "        model_1 = buildModel(hiddenLayers, unitsPerHL, unitsInputLayer, batch_size)\n",
    "        #Fit\n",
    "        model_1, history = fitModel(model_1, trainX_scaled, trainY, valX_scaled, valY, epochs, batch_size, shuffle=shuffle)\n",
    "        \n",
    "        #Print nework structure\n",
    "        model_1.summary()\n",
    "        \n",
    "        \n",
    "        test_eval = model_1.evaluate(testX_scaled, testY, batch_size=batch_size)\n",
    "        \n",
    "        #Predict.\n",
    "        res1 = predictModel(model_1, testX_scaled, nShifts, batch_size)\n",
    "        \n",
    "        #Plot predicitons. \n",
    "        #plotPredict(res1, testY, nShifts, windowSize, epochs, hiddenLayers, unitsPerHL, unitsInputLayer, batch_size, timeStamp, shuffle, onlyAfricaTest, onlyAfricaVal, onlyAfricaTrain)\n",
    "        \n",
    "        #Plot metrics.\n",
    "        plotMetrics(history, timeStamp)\n",
    "        #print(args)\n",
    "        \n",
    "     \n",
    "        \n",
    "        metrics = {\"Brier\": calcBrierScore(res1, testY), \"Metrics\": getEvaluateMetric(model_1, test_eval)}\n",
    "        \n",
    "        return model_1, metrics\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"full_dataset.csv\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getAllData(\"dummy_type_1\", path)[\"month\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AFRIKA--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "args_t1_sb_A = {\n",
    "        \"targetVar\" : \"dummy_type_1\",\n",
    "        \"onlyAfricaTest\" : True,\n",
    "        \"onlyAfricaVal\" : False,\n",
    "        \"onlyAfricaTrain\" : False,\n",
    "        #Storleken på fönstret som ska inkluderas i ett sample.\n",
    "        \"windowSize\" : 3,\n",
    "        #Antalet förskjutningar.\n",
    "        \"nShifts\" : 1, \n",
    "        \"epochs\" : 7,\n",
    "        \"hiddenLayers\" : 2,\n",
    "        \"unitsPerHL\" : 6,\n",
    "        \"unitsInputLayer\" : 6,\n",
    "        #Blanda samples?\n",
    "        \"shuffle\" : True,\n",
    "        \"batch_size\" : 40,\n",
    "        \"timeStamp\" : strftime(\"%Y-%m-%d %H:%M:%S\", localtime()),\n",
    "        \"kerasTuner\": False\n",
    "}\n",
    "\n",
    "model_t1_sb_A, metrics_t1_sb_A = runModel(args_t1_sb_A)\n",
    "metrics_t1_sb_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_t6_sb_A = {\n",
    "        \"targetVar\" : \"dummy_type_1\",\n",
    "        \"onlyAfricaTest\" : True,\n",
    "        \"onlyAfricaVal\" : False,\n",
    "        \"onlyAfricaTrain\" : False,\n",
    "        #Storleken på fönstret som ska inkluderas i ett sample.\n",
    "        \"windowSize\" : 3,\n",
    "        #Antalet förskjutningar.\n",
    "        \"nShifts\" : 6, \n",
    "        \"epochs\" : 6,\n",
    "        \"hiddenLayers\" : 3,\n",
    "        \"unitsPerHL\" : 7,\n",
    "        \"unitsInputLayer\" : 6,\n",
    "        #Blanda samples?\n",
    "        \"shuffle\" : True,\n",
    "        \"batch_size\" : 40,\n",
    "        \"timeStamp\" : strftime(\"%Y-%m-%d %H:%M:%S\", localtime()),\n",
    "        \"kerasTuner\": False\n",
    "}\n",
    "\n",
    "model_t6_sb_A, metrics_t6_sb_A = runModel(args_t6_sb_A)\n",
    "metrics_t6_sb_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_t12_sb_A = {\n",
    "        \"targetVar\" : \"dummy_type_1\",\n",
    "        \"onlyAfricaTest\" : True,\n",
    "        \"onlyAfricaVal\" : False,\n",
    "        \"onlyAfricaTrain\" : False,\n",
    "        #Storleken på fönstret som ska inkluderas i ett sample.\n",
    "        \"windowSize\" : 3,\n",
    "        #Antalet förskjutningar.\n",
    "        \"nShifts\" : 12, \n",
    "        \"epochs\" : 7,\n",
    "        \"hiddenLayers\" : 1,\n",
    "        \"unitsPerHL\" : 5,\n",
    "        \"unitsInputLayer\" : 6,\n",
    "        #Blanda samples?\n",
    "        \"shuffle\" : True,\n",
    "        \"batch_size\" : 40,\n",
    "        \"timeStamp\" : strftime(\"%Y-%m-%d %H:%M:%S\", localtime()),\n",
    "        \"kerasTuner\": False\n",
    "}\n",
    "\n",
    "model_t12_sb_A, metrics_t12_sb_A = runModel(args_t12_sb_A)\n",
    "metrics_t12_sb_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
